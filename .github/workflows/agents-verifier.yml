name: Agents Verifier

on:
  pull_request:
    types:
      - closed
  push:
    branches:
      - main

permissions:
  contents: read
  pull-requests: read
  issues: write

jobs:
  verifier:
    name: Run post-merge verifier
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Build verifier context
        id: context
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const { buildVerifierContext } = require('./.github/scripts/agents_verifier_context.js');
            await buildVerifierContext({ github, context, core });

      - name: Stop when verifier is skipped
        if: steps.context.outputs.should_run != 'true'
        run: |
          echo "Verifier skipped: ${{ steps.context.outputs.skip_reason || 'no reason provided' }}"

      - name: Prepare verifier prompt
        if: steps.context.outputs.should_run == 'true'
        id: prepare
        run: |
          set -euo pipefail
          base_prompt=".github/codex/prompts/verifier_acceptance_check.md"
          context_file="${{ steps.context.outputs.context_path }}"
          combined="verifier-prompt.md"
          if [ ! -f "$base_prompt" ]; then
            echo "::error::Base prompt file missing: $base_prompt"
            exit 1
          fi
          if [ ! -f "$context_file" ]; then
            echo "::error::Context file missing: $context_file"
            exit 1
          fi
          {
            cat "$base_prompt"
            printf '\n\n---\n\n'
            cat "$context_file"
          } > "$combined"
          echo "prompt_file=$combined" >> "$GITHUB_OUTPUT"

      - name: Setup Codex auth
        id: codex_auth
        if: steps.context.outputs.should_run == 'true'
        env:
          CODEX_AUTH_JSON: ${{ secrets.CODEX_AUTH_JSON }}
          CODEX_HOME: ${{ runner.temp }}/.codex-verifier
        run: |
          set -euo pipefail

          # Setup auth in default location
          mkdir -p ~/.codex
          echo "$CODEX_AUTH_JSON" > ~/.codex/auth.json
          chmod 600 ~/.codex/auth.json

          # Also setup in CODEX_HOME for the action
          mkdir -p "$CODEX_HOME"
          cp ~/.codex/auth.json "$CODEX_HOME/auth.json"
          chmod 600 "$CODEX_HOME/auth.json"

          echo "Codex auth configured from CODEX_AUTH_JSON secret"
          echo "Auth files created at ~/.codex/auth.json and $CODEX_HOME/auth.json"

          # Check token expiration
          python3 << 'PYEOF'
          import json, base64, datetime, sys, os

          auth_path = os.path.expanduser("~/.codex/auth.json")
          try:
              with open(auth_path) as f:
                  auth = json.load(f)
              token = auth.get("tokens", {}).get("access_token", "")
              if not token:
                  print("::warning::No access token found in auth.json")
                  sys.exit(0)

              parts = token.split(".")
              if len(parts) != 3:
                  print("::warning::Invalid JWT format in access token")
                  sys.exit(0)

              payload = parts[1] + "=" * (4 - len(parts[1]) % 4)
              data = json.loads(base64.urlsafe_b64decode(payload))
              exp_time = datetime.datetime.fromtimestamp(data["exp"], tz=datetime.timezone.utc)
              now = datetime.datetime.now(tz=datetime.timezone.utc)
              diff = exp_time - now
              days_left = diff.days
              hours_left = diff.total_seconds() / 3600

              print(f"Token expires: {exp_time.isoformat()}")
              print(f"Days until expiration: {days_left}")

              if days_left < 0:
                  print("::error::CODEX_AUTH_JSON has expired! Run 'codex login --device-auth' and update the secret. See docs/ci/CHATGPT_SUBSCRIPTION_CI.md for instructions.")
                  sys.exit(1)
              elif days_left < 2:
                  print(f"::warning::CODEX_AUTH_JSON expires in {hours_left:.0f} hours! Consider refreshing soon.")
                  print("Run 'codex login --device-auth' and update the CODEX_AUTH_JSON secret.")
              elif days_left < 5:
                  print(f"::notice::CODEX_AUTH_JSON expires in {days_left} days. Plan to refresh before expiration.")

              # Expose token expiration details for downstream GitHub Actions steps
              try:
                  # Prefer the existing days_left calculation, but recompute from exp/now if needed
                  days_until_expiry = days_left
              except NameError:
                  try:
                      days_until_expiry = (exp - now).days
                  except Exception:
                      days_until_expiry = None

              token_expires_value = None
              try:
                  # If exp is a datetime, serialize as ISO 8601; otherwise fall back to str()
                  if isinstance(exp, datetime.datetime):
                      token_expires_value = exp.isoformat()
                  else:
                      token_expires_value = str(exp)
              except Exception:
                  token_expires_value = None

              github_output = os.environ.get("GITHUB_OUTPUT")
              if github_output and (token_expires_value is not None or days_until_expiry is not None):
                  try:
                      with open(github_output, "a", encoding="utf-8") as fh:
                          if token_expires_value is not None:
                              fh.write(f"token_expires={token_expires_value}\n")
                          if days_until_expiry is not None:
                              fh.write(f"days_until_expiry={days_until_expiry}\n")
                  except Exception as e:
                      # Do not fail the job if we cannot write outputs; just emit a warning
                      print(f"::warning::Failed to write token expiration outputs: {e}")
          except Exception as e:
              print(f"::warning::Could not check token expiration: {e}")
          PYEOF

      - name: Install Codex CLI
        if: steps.context.outputs.should_run == 'true'
        run: npm install -g @openai/codex

      - name: Run verifier
        id: codex
        if: steps.context.outputs.should_run == 'true'
        env:
          CODEX_HOME: ${{ runner.temp }}/.codex-verifier
        run: |
          set -euo pipefail
          # Run codex exec directly with the pre-configured auth.json
          # Use read-only sandbox for safety
          codex exec \
            --sandbox read-only \
            --skip-git-repo-check \
            --output-last-message codex-output.md \
            < "${{ steps.prepare.outputs.prompt_file }}"

          echo "Codex verifier completed"
          if [ -f codex-output.md ]; then
            echo "=== Verifier Output ==="
            cat codex-output.md
          fi

      - name: Parse verifier verdict
        id: verdict
        if: steps.context.outputs.should_run == 'true'
        run: |
          set -euo pipefail
          verdict="unknown"
          output_file="codex-output.md"
          if [ -f "$output_file" ]; then
            if grep -qiE 'verdict:\\s*fail' "$output_file"; then
              verdict="fail"
            elif grep -qiE 'verdict:\\s*pass' "$output_file"; then
              verdict="pass"
            fi
          fi
          echo "verdict=$verdict" >> "$GITHUB_OUTPUT"

      - name: Open follow-up issue on verifier failure
        id: failure_issue
        if: steps.context.outputs.should_run == 'true' && steps.verdict.outputs.verdict == 'fail'
        uses: actions/github-script@v7
        env:
          PR_URL: ${{ steps.context.outputs.pr_html_url }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const prNumber = Number('${{ steps.context.outputs.pr_number }}') || null;
            const issueNumbers = JSON.parse('${{ steps.context.outputs.issue_numbers || '[]' }}');
            const title = prNumber
              ? `Verifier failure for PR #${prNumber}`
              : 'Verifier failure on merged commit';
            const lines = [];
            if (process.env.PR_URL) {
              lines.push(`Source pull request: ${process.env.PR_URL}`);
            }
            if (Array.isArray(issueNumbers) && issueNumbers.length) {
              lines.push(`Linked issues: ${issueNumbers.map((n) => `#${n}`).join(', ')}`);
            }
            lines.push('');
            lines.push('## Verifier output');
            lines.push('');
            lines.push('```');
            lines.push(require('fs').readFileSync('codex-output.md', 'utf8'));
            lines.push('```');
            lines.push('');
            lines.push('- [ ] Re-run verifier after addressing the failures.');
            const body = lines.join('\n');
            const { data: issue } = await github.rest.issues.create({
              ...context.repo,
              title,
              body,
              labels: ['agent:codex'],
            });
            core.setOutput('issue_number', issue?.number ? String(issue.number) : '');

      - name: Collect verifier metrics
        if: always()
        id: collect_metrics
        env:
          SHOULD_RUN: ${{ steps.context.outputs.should_run }}
          PR_NUMBER: ${{ steps.context.outputs.pr_number }}
          VERDICT: ${{ steps.verdict.outputs.verdict }}
          CONTEXT_PATH: ${{ steps.context.outputs.context_path }}
          CODEX_OUTPUT: codex-output.md
          ISSUE_NUMBER: ${{ steps.failure_issue.outputs.issue_number }}
          SKIP_REASON: ${{ steps.context.outputs.skip_reason }}
        run: |
          set -euo pipefail
          python - <<'PY'
          import json
          import os
          import re
          from pathlib import Path
          from datetime import datetime, timezone

          def count_checkboxes(text: str) -> int:
              return sum(1 for line in text.splitlines() if re.match(r"^- \\[[ xX]\\]", line.strip()))

          should_run = (os.environ.get("SHOULD_RUN") or "").lower() == "true"
          pr_number = int(os.environ.get("PR_NUMBER") or 0)
          verdict = os.environ.get("VERDICT") or "unknown"
          context_path = Path(os.environ.get("CONTEXT_PATH") or "")
          skip_reason = os.environ.get("SKIP_REASON") or ""
          issue_number = os.environ.get("ISSUE_NUMBER") or ""

          if not should_run:
              verdict = "skipped"

          issues_created = 1 if issue_number else 0
          issue_numbers = [issue_number] if issue_number else []

          acceptance_criteria_count = 0
          if context_path.is_file():
              acceptance_criteria_count = count_checkboxes(context_path.read_text(encoding="utf-8"))

          checks_run = 0
          codex_output_path = Path(os.environ.get("CODEX_OUTPUT") or "")
          if codex_output_path.is_file():
              content = codex_output_path.read_text(encoding="utf-8")
              checks_run = sum(1 for line in content.splitlines()[1:] if line.lstrip().startswith("- "))

          metrics = {
              "pr_number": pr_number,
              "verdict": verdict,
              "issues_created": issues_created,
              "issue_numbers": issue_numbers,
              "acceptance_criteria_count": acceptance_criteria_count,
              "checks_run": checks_run,
              "skip_reason": skip_reason,
              "recorded_at": datetime.now(timezone.utc).isoformat(),
          }

          print(json.dumps(metrics, indent=2))
          with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as fp:
              fp.write(f"metrics_json={json.dumps(metrics)}\n")
          PY

      - name: Write verifier summary
        if: always()
        env:
          METRICS_JSON: ${{ steps.collect_metrics.outputs.metrics_json }}
        run: |
          set -euo pipefail
          if [ -z "${METRICS_JSON:-}" ]; then
            echo "No verifier metrics captured; skipping summary."
            exit 0
          fi
          python - <<'PY'
          import json
          import os

          metrics = json.loads(os.environ["METRICS_JSON"])
          order = [
              "pr_number",
              "verdict",
              "issues_created",
              "issue_numbers",
              "acceptance_criteria_count",
              "checks_run",
              "skip_reason",
              "recorded_at",
          ]

          lines = ["## Verifier metrics", ""] + ["| Field | Value |", "| --- | --- |"]
          for key in order:
              value = metrics.get(key, "")
              lines.append(f"| {key} | `{value}` |")

          summary_path = os.environ.get("GITHUB_STEP_SUMMARY")
          if summary_path:
              with open(summary_path, "a", encoding="utf-8") as fp:
                  fp.write("\n".join(lines) + "\n")

          out_path = "verifier-metrics.ndjson"
          with open(out_path, "a", encoding="utf-8") as fp:
              fp.write(json.dumps(metrics) + "\n")
          print(f"Wrote metrics to {out_path}")
          PY

      - name: Upload verifier metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: agents-verifier-metrics
          path: verifier-metrics.ndjson
          retention-days: 30
